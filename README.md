å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸ºè¿™ä¸ªé¡¹ç›®å‡†å¤‡çš„ `README.md` æ–‡ä»¶ã€‚ä½ å¯ä»¥å°†å®ƒä¿å­˜åœ¨é¡¹ç›®çš„æ ¹ç›®å½•ä¸‹ã€‚

---

# Fake Hugging Face Hub (ä¼ª Hugging Face Hub æœåŠ¡)

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ FastAPI æ„å»ºçš„ç®€å• Web æœåŠ¡ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿ [Hugging Face Hub](https://huggingface.co/) çš„æ ¸å¿ƒåŠŸèƒ½ã€‚å¯ä½œä¸ºæœ¬åœ°ã€ç¦»çº¿æˆ–ç§æœ‰çš„æ¨¡å‹/æ•°æ®é›†ä»“åº“ï¼Œå¹¶ä¸å®˜æ–¹ä¸‹è½½å®¢æˆ·ç«¯ä¿æŒå…¼å®¹ã€‚API ç»“æ„å¯¹é½ `hf-mirror.com`ï¼Œæ”¯æŒæ–°ç‰ˆ `hf` å®¢æˆ·ç«¯çš„ `HEAD` æ¢æµ‹ã€`Range` åˆ†æ®µä¸ä¿®è®¢æŸ¥è¯¢ã€‚


## âœ¨ åŠŸèƒ½ç‰¹æ€§

*   **æœ¬åœ°æ¨¡å‹/æ•°æ®é›†æ‰˜ç®¡**: åœ¨ä½ è‡ªå·±çš„æœåŠ¡å™¨ä¸Šæ‰˜ç®¡ Hugging Face æ¨¡å‹ä¸æ•°æ®é›†ã€‚
*   **CLI å…¼å®¹**: æ”¯æŒæ–°ç‰ˆ `hf download`ï¼ˆæ¨èï¼‰ä¸æ—§ç‰ˆ `huggingface-cli download`ï¼ˆå°†æç¤ºå·²å¼ƒç”¨ï¼‰ã€‚
*   **API å¯¹é½**:
    - æ¨¡å‹ï¼š`/api/models/{repo_id}` ä¸ `/api/models/{repo_id}/revision/{revision}` è¿”å›å­—æ®µé›†åˆä¸ç±»å‹å¯¹é½ `hf-mirror.com`ï¼›`siblings` ä»…åŒ…å« `rfilename`ã€‚
    - æ•°æ®é›†ï¼š`/api/datasets/{dataset_id}` ä¸ `/api/datasets/{dataset_id}/revision/{revision}` è¿”å›å¸¸è§å­—æ®µï¼ˆ`id`ã€`sha`ã€`lastModified`ã€`cardData`ã€`siblings` ç­‰ï¼‰ã€‚
    - è·¯å¾„ä¿¡æ¯ï¼šå…¼å®¹ `paths-info` æ¥å£ï¼Œä¾›å®¢æˆ·ç«¯æ‰¹é‡æŸ¥è¯¢è·¯å¾„å…ƒæ•°æ®ï¼š
      - æ¨¡å‹ï¼š`POST /api/models/{repo_id}/paths-info/{revision}`
      - æ•°æ®é›†ï¼š`POST /api/datasets/{repo_id}/paths-info/{revision}`
      - è¯·æ±‚ä½“ç¤ºä¾‹ï¼š`{"paths": ["", "subdir/"], "expand": true}`ï¼›å“åº”ä¸ºè‹¥å¹² `{path, type, size?}` æ¡ç›®ã€‚
*   **Range/HEAD æ”¯æŒ**: ä¸‹è½½è·¯ç”±æ”¯æŒæ ‡å‡† `Range`ï¼ˆ`bytes=`ï¼‰ä¸ `HEAD`ï¼š
    - `HEAD` è¿”å› `Content-Length`ã€`Content-Type`ã€`Accept-Ranges`ã€`ETag` ç­‰å…³é”®å¤´éƒ¨ã€‚
    - `GET` è§£æ `Range: bytes=...`ï¼Œè¿”å› `206 Partial Content` ä¸ `Content-Range`ï¼Œä¸æ»¡è¶³æ—¶è¿”å› `416`ã€‚
*   **è½»é‡çº§**: åŸºäº FastAPI æ„å»ºï¼Œæ€§èƒ½é«˜ä¸”æ˜“äºéƒ¨ç½²ã€‚
*   **ç®€å•çš„ä»“åº“ç»“æ„**: åªéœ€å°†æ¨¡å‹æ–‡ä»¶æ”¾åœ¨ç›¸åº”çš„æ–‡ä»¶å¤¹ä¸­ï¼ŒæœåŠ¡ä¼šè‡ªåŠ¨å‘ç°å®ƒä»¬ã€‚
*   **æ˜“äºæ‰©å±•**: å¯ä»¥è½»æ¾æ·»åŠ æ›´å¤šè·¯ç”±æˆ–åŠŸèƒ½æ¥æ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚

## âš™ï¸ ç¯å¢ƒå‡†å¤‡

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ å·²ç»å®‰è£…äº†ä»¥ä¸‹å·¥å…·ï¼š

*   Python 3.12+
*   pip
*   `huggingface-hub` Python åº“ï¼ˆåŒ…å« `huggingface-cli`ï¼›æ–°ç‰ˆè¿˜æä¾› `hf` å‘½ä»¤ï¼‰

å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£… `huggingface-hub`ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š
```bash
pip install huggingface-hub
```

## ğŸš€ å®‰è£…ä¸è®¾ç½®

1.  **å…‹éš†æˆ–åˆ›å»ºé¡¹ç›®æ–‡ä»¶**:
    å°† `main.py` å’Œ `fake_hub` ç›®å½•æ”¾åœ¨ä½ çš„é¡¹ç›®æ ¹ç›®å½•ä¸‹ã€‚

2.  **åˆ›å»ºé¡¹ç›®ç»“æ„**:
    ä½ çš„é¡¹ç›®ç›®å½•åº”è¯¥çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

    ```
    .
    â”œâ”€â”€ fake_hub/                             # ä»“åº“æ ¹ç›®å½•
    â”‚   â”œâ”€â”€ gpt2/                             # æ¨¡å‹ä»“åº“ (ä¾‹å¦‚ 'gpt2')
    â”‚   â”‚   â”œâ”€â”€ config.json
    â”‚   â”‚   â”œâ”€â”€ pytorch_model.bin
    â”‚   â”‚   â””â”€â”€ .gitattributes
    â”‚   â””â”€â”€ datasets/
    â”‚       â””â”€â”€ HuggingFaceFW/finepdfs/       # æ•°æ®é›†ä»“åº“ (å‘½åç©ºé—´/åç§°)
    â”‚           â”œâ”€â”€ README.md
    â”‚           â”œâ”€â”€ dataset_infos.json
    â”‚           â””â”€â”€ data/
    â”‚               â””â”€â”€ sample.jsonl
    â”œâ”€â”€ main.py                  # FastAPI æœåŠ¡ä»£ç 
    â””â”€â”€ README.md                # æœ¬æ–‡æ¡£
    ```

3.  **å®‰è£…ä¾èµ–**:
    é¡¹ç›®ä½¿ç”¨uvç®¡ç†ä¾èµ–
    ```bash
    uv sync
    ```

## â–¶ï¸ å¦‚ä½•ä½¿ç”¨

1.  **å¯åŠ¨æœåŠ¡**:
    åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼Œè¿è¡Œ `main.py` æ¥å¯åŠ¨ FastAPI æœåŠ¡ã€‚

    ```bash
    uv run python -m uvicorn main:app --reload

    # å±€åŸŸç½‘/å®¹å™¨è®¿é—®ï¼ˆç›‘å¬ 0.0.0.0:8000ï¼‰
    uv run python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ```

    æœåŠ¡å¯åŠ¨åï¼Œä½ å°†çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼Œè¡¨æ˜æœåŠ¡æ­£åœ¨ `http://127.0.0.1:8000` ä¸Šè¿è¡Œï¼š
    ```
    Fake Hugging Face Hub æ­£åœ¨è¿è¡Œåœ¨ http://127.0.0.1:8000
    [fake-hub] FAKE_HUB_ROOT = /path/to/your/project/fake_hub
    ä½ å¯ä»¥é€šè¿‡è®¾ç½® HF_ENDPOINT ç¯å¢ƒå˜é‡æ¥ä»æœ¬æœåŠ¡ä¸‹è½½:

      export HF_ENDPOINT=http://127.0.0.1:8000
      huggingface-cli download gpt2
    ```

    å¯é€‰ï¼šè¯·æ±‚è¯¦ç»†æ—¥å¿—ï¼ˆå¯å…³è” Request-IDï¼‰
    - æœåŠ¡è®°å½•ï¼š`method path?query`ã€client IP:portã€åè®®ç‰ˆæœ¬ã€schemeã€å¤„ç†æ—¶é•¿ï¼›å¹¶æ‰“å°è¯·æ±‚ä¸å“åº”å¤´ã€‚
    - é»˜è®¤ä¼šè®°å½•ä»»æ„ Content-Type çš„è¯·æ±‚ä½“å‰ `LOG_BODY_MAX` å­—èŠ‚ï¼ˆUTF-8 è§£ç ï¼Œæ— æ³•è§£ç å¤„æ›¿æ¢ï¼‰ã€‚
    - æ¯æ¡è¯·æ±‚æ—¥å¿—å¸¦ `X-Request-ID`ï¼ŒåŒæ—¶å†™å…¥å“åº”å¤´ä¾¿äºæ’æŸ¥é“¾è·¯ã€‚
    - ç¯å¢ƒå˜é‡æ§åˆ¶ï¼š
      ```bash
      export LOG_REQUESTS=1        # 1/true å¼€å¯ï¼ˆé»˜è®¤ï¼‰ï¼Œ0 å…³é—­
      export LOG_BODY_MAX=4096     # è¯·æ±‚ä½“æœ€å¤§è®°å½•å­—èŠ‚æ•°ï¼ˆé»˜è®¤ 4096ï¼‰
      export LOG_HEADERS=all       # all|minimalï¼ˆé»˜è®¤ allï¼Œè®°å½•å…¨éƒ¨è¯·æ±‚å¤´ï¼‰
      export LOG_RESP_HEADERS=1    # è®°å½•å“åº”å¤´ï¼ˆé»˜è®¤ 1ï¼‰
      export LOG_REDACT=1          # è„±æ• Authorization/Cookie ç­‰ï¼ˆé»˜è®¤ 1ï¼‰
      export LOG_BODY_ALL=1        # æ‰€æœ‰ Content-Type éƒ½å°è¯•è®°å½•ä½“ï¼ˆé»˜è®¤ 1ï¼‰
      ```

2.  **é…ç½®å®¢æˆ·ç«¯**:
    æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯çª—å£ï¼Œè®¾ç½® `HF_ENDPOINT` ç¯å¢ƒå˜é‡ï¼Œå°†å®¢æˆ·ç«¯æŒ‡å‘ä½ çš„æœ¬åœ°æœåŠ¡ã€‚

    ```bash
    export HF_ENDPOINT=http://127.0.0.1:8000
    ```
    **æ³¨æ„**: è¿™ä¸ªç¯å¢ƒå˜é‡åªåœ¨å½“å‰çš„ç»ˆç«¯ä¼šè¯ä¸­æœ‰æ•ˆã€‚

3.  **ä¸‹è½½æ¨¡å‹/æ•°æ®é›†**:
    ç°åœ¨ï¼Œä½ å¯ä»¥åƒä»å®˜æ–¹ Hub ä¸‹è½½ä¸€æ ·ä½¿ç”¨å®¢æˆ·ç«¯ã€‚

    *   **ä¸‹è½½æ•´ä¸ªä»“åº“ï¼ˆæ¨èï¼‰**:
        ```bash
        hf download gpt2 --local-dir ./downloaded_gpt2
        ```

    *   **æ—§ç‰ˆå‘½ä»¤ï¼ˆä¼šæç¤ºå·²å¼ƒç”¨ï¼‰**:
        ```bash
        huggingface-cli download gpt2 --local-dir ./downloaded_gpt2
        ```

    *   **ä¸‹è½½ç‰¹å®šæ–‡ä»¶**:
        ```bash
        hf download gpt2 --include config.json --local-dir ./downloaded_gpt2
        ```

    *   **ä¸‹è½½æ•°æ®é›†ï¼ˆç¤ºä¾‹ï¼‰**:
        ```bash
        hf download --repo-type dataset "HuggingFaceFW/finepdfs" --local-dir ./downloaded_finepdfs
        ```
    *   **ç»„ç»‡å/ä»“åº“å**ï¼šæ¨¡å‹ä¸æ•°æ®é›†çš„ `repo_id` æ”¯æŒç»„ç»‡åå‰ç¼€ï¼ˆå¦‚ `openai/gpt-oss-20b`ï¼‰ã€‚

    *   **æŸ¥çœ‹ä¸‹è½½æµé‡**:
        å½“ä½ æ‰§è¡Œä¸‹è½½å‘½ä»¤æ—¶ï¼Œå¯ä»¥åœ¨è¿è¡Œ FastAPI æœåŠ¡çš„ç»ˆç«¯ä¸­çœ‹åˆ°è®¿é—®æ—¥å¿—ï¼Œä¾‹å¦‚ï¼š
        ```
        INFO:     127.0.0.1:xxxxx - "GET /api/models/gpt2 HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /api/models/gpt2/revision/main HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /gpt2/resolve/main/config.json HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /gpt2/resolve/main/pytorch_model.bin HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /api/datasets/HuggingFaceFW/finepdfs HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /datasets/HuggingFaceFW/finepdfs/resolve/main/README.md HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "GET /datasets/HuggingFaceFW/finepdfs/resolve/main/data/sample.jsonl HTTP/1.1" 200 OK
        INFO:     127.0.0.1:xxxxx - "POST /api/models/openai/gpt-oss-20b/paths-info/fakesha-main HTTP/1.1" 200 OK
        ...
        ```

## ğŸ§° ä¸€é”®éª¨æ¶å…‹éš†ï¼ˆåªå¤åˆ¶æ–‡ä»¶ç»“æ„ï¼‰

å½“ä½ æƒ³å¿«é€Ÿåœ¨æœ¬åœ°æ­ä¸€ä¸ªâ€œä¸çœŸå®ä»“åº“åŒç»“æ„â€çš„å‡ repoï¼ˆä»…ç›®å½•ä¸æ–‡ä»¶åï¼Œä¸å«çœŸå®å†…å®¹ï¼‰æ—¶ï¼Œå¯ä»¥ä½¿ç”¨å†…ç½®çš„ CLIï¼š

```bash
# æ–¹å¼ Aï¼ˆæ¨èï¼Œå…å®‰è£…æœ¬åœ°åŒ…ï¼‰ï¼šä½¿ç”¨æ¨¡å—è¿è¡Œ
uv run python -m skeleton gpt2 --repo-type model
uv run python -m skeleton HuggingFaceFW/finepdfs --repo-type dataset

# æ–¹å¼ Bï¼ˆå®‰è£…å¯æ‰§è¡Œè„šæœ¬åä½¿ç”¨ï¼‰
uv pip install -e .
uv run fakehub-skeleton gpt2 --repo-type model

# å¸¸ç”¨å‚æ•°
uv run python -m skeleton <repo_id> --repo-type {model|dataset} \
  --revision main \
  --endpoint https://huggingface.co \
  --include "*.json" --include "*.md" \
  --exclude "*.bin" \
  --max-files 100 \
  --dst ./fake_hub/custom_root \
  --force \
  --fill --fill-size 16MiB --fill-content "FAKE"

uv run python -m skeleton tencent/HunyuanImage-2.1 --repo-type model --fill --fill-size 1024MiB --fill-content "FAKE"
```

è¯´æ˜ï¼š
- å‘½ä»¤ä¼šä»è¿œç«¯ API è·å–ä»“åº“çš„æ ‘ç»“æ„ï¼Œåˆ›å»ºç©ºæ–‡ä»¶ï¼Œæˆ–æŒ‰éœ€ç”¨å›ºå®šå†…å®¹å¡«å……ï¼ˆ`--fill`ï¼‰ã€‚
- é»˜è®¤è¾“å‡ºè·¯å¾„éµå¾ªæœåŠ¡çº¦å®šï¼šæ¨¡å‹åœ¨ `fake_hub/<repo_id>`ï¼Œæ•°æ®é›†åœ¨ `fake_hub/datasets/<namespace>/<name>`ã€‚
- é€šè¿‡ `--endpoint` å¯åˆ‡æ¢åˆ°é•œåƒç«™ï¼Œä¾‹å¦‚ `https://hf-mirror.com`ã€‚
- ä½¿ç”¨ `--include/--exclude` è¿›è¡Œæ–‡ä»¶é€‰æ‹©ï¼›`--max-files` å¯é™åˆ¶æ•°é‡ã€‚
- ä¸å†æ”¯æŒâ€œä»æœ¬åœ°ç›®å½•ç”Ÿæˆéª¨æ¶â€çš„æ¨¡å¼ã€‚

### é¢„ç”Ÿæˆ LFS/OID å…ƒæ•°æ®ï¼ˆä¸æœ¬åœ°æ–‡ä»¶çœŸå®ä¸€è‡´ï¼‰

- skeleton CLI åœ¨åˆ›å»ºå ä½æ–‡ä»¶åï¼Œä¼šåŸºäºâ€œç£ç›˜ä¸Šçš„å®é™…æ–‡ä»¶â€è®¡ç®—å“ˆå¸Œå¹¶ç”Ÿæˆ `/.paths-info.json`ï¼Œæ¯ä¸ªæ–‡ä»¶é¡¹åŒ…å«ï¼š
  - `size`: å®é™…æ–‡ä»¶å¤§å°
  - `oid`: æ–‡ä»¶å†…å®¹çš„ SHAâ€‘1
  - `lfs.oid`: å½¢å¦‚ `sha256:<hex>` çš„ SHAâ€‘256 å€¼
  - `lfs.size`: å®é™…æ–‡ä»¶å¤§å°
- æœåŠ¡ç«¯åœ¨å¤„ç† `paths-info` æ—¶ä¼šä¼˜å…ˆè¯»å– sidecarï¼Œå¹¶ä»…åœ¨ sidecar çš„ `size` ä¸ç£ç›˜å®é™…å¤§å°ä¸€è‡´æ—¶ä¿¡ä»»å…¶ä¸­çš„å“ˆå¸Œï¼›è‹¥ç¼ºå¤±æˆ–ä¸ä¸€è‡´ï¼Œåˆ™å³æ—¶é‡æ–°è®¡ç®—ï¼Œç¡®ä¿å¯¹å®¢æˆ·ç«¯ç»™å‡ºçš„å…ƒæ•°æ®å‡†ç¡®æ— è¯¯ã€‚
- æ— è®ºæ˜¯å¦æä¾› `paths` æˆ– `expand`ï¼Œ`paths-info` å“åº”ä¸­æ¯ä¸ªæ–‡ä»¶éƒ½ä¼šåŒ…å« `oid`ï¼ˆæˆ–åœ¨ `lfs` å­å¯¹è±¡ä¸­æºå¸¦ `oid`ï¼‰ã€‚

### å¡«å……æ–‡ä»¶å†…å®¹ï¼ˆå¯é€‰ï¼‰

- `--fill`: å°†åˆ›å»ºçš„æ–‡ä»¶ç”¨é‡å¤å†…å®¹å¡«å……ï¼ˆé»˜è®¤ä¸ºç©ºæ–‡ä»¶ï¼‰ã€‚
- `--fill-size`: æ¯ä¸ªæ–‡ä»¶å¡«å……çš„å¤§å°ï¼Œæ”¯æŒ `B/KB/MB/GB` æˆ– `KiB/MiB/GiB`ï¼Œå¦‚ `16MiB`ã€‚æœªæŒ‡å®šæ—¶é»˜è®¤ `16MiB`ã€‚
- `--fill-content`: ç”¨äºé‡å¤å¡«å……çš„å­—ç¬¦ä¸²ï¼ˆUTF-8 ç¼–ç ï¼‰ï¼ŒæœªæŒ‡å®šæ—¶ä»¥ 0 å­—èŠ‚å¡«å……ã€‚

---

## ğŸ§° å‡†å¤‡æœ¬åœ°ä»“åº“ç»“æ„

å°†éœ€è¦æš´éœ²ç»™å®¢æˆ·ç«¯çš„æ¨¡å‹æˆ–æ•°æ®é›†æ–‡ä»¶ç›´æ¥æ”¾å…¥ä»¥ä¸‹ç›®å½•ç»“æ„ä¸­ï¼š

```
fake_hub/
  <model_repo_id>/
    config.json
    *.bin
    subdirs/...ï¼ˆå¯é€‰ï¼‰
  datasets/
    <namespace>/<dataset_name>/
      README.md
      data/...ï¼ˆå¯é€‰ï¼‰
```

è¯´æ˜ï¼š
- æ¨¡å‹ä½äº `fake_hub/<repo_id>`ï¼›æ•°æ®é›†ä½äº `fake_hub/datasets/<namespace>/<name>`ã€‚
- æœåŠ¡ä¼šé€’å½’å‘ç°å­ç›®å½•ä¸­æ–‡ä»¶å¹¶åœ¨ `siblings`ï¼ˆä»… `rfilename`ï¼‰ä¸ `paths-info` ä¸­è¿”å›ã€‚
- å¦‚ä»“åº“æ ¹å­˜åœ¨ `/.paths-info.json`ï¼ŒæœåŠ¡ç«¯å°†ä¼˜å…ˆä½¿ç”¨ä¸”æ ¡éªŒå…¶ `size` ä¸å®é™…æ–‡ä»¶ä¸€è‡´ï¼›ä¸ä¸€è‡´æ—¶å°†å¿½ç•¥å¹¶é‡æ–°è®¡ç®—å“ˆå¸Œã€‚

## ğŸ”§ å·¥ä½œåŸç†

å®¢æˆ·ç«¯ä¸‹è½½æµç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

1.  å®¢æˆ·ç«¯è¯·æ±‚ `{HF_ENDPOINT}/api/models/{repo_id}` æˆ– `{HF_ENDPOINT}/api/datasets/{dataset_id}` è·å–æ–‡ä»¶æ¸…å•ï¼›éƒ¨åˆ†ç‰ˆæœ¬ä¼šç»§ç»­è¯·æ±‚ `{HF_ENDPOINT}/api/.../revision/{revision}`ï¼ˆå½“å‰å®ç°ä¼šå¿½ç•¥ `revision`ï¼‰ã€‚
    - æŸäº›å®¢æˆ·ç«¯ä¼šè°ƒç”¨ `POST /api/(models|datasets)/{repo_id}/paths-info/{revision}` æŸ¥è¯¢è·¯å¾„å…ƒä¿¡æ¯ï¼ˆå« `size`ï¼‰ã€‚æœ¬æœåŠ¡å·²å®ç°æœ€å°å­é›†ä»¥æ»¡è¶³æ–°ç‰ˆ `hf` çš„è°ƒç”¨ã€‚
2.  æœåŠ¡æ‰«æ `fake_hub/{repo_id}` ç›®å½•ï¼Œè¿”å›ä¸ `hf-mirror.com` ç»“æ„ä¸€è‡´çš„ JSONï¼ˆå¦‚ `_id`ã€`id`ã€`modelId`ã€`sha`ã€`tags`ã€`siblings` ç­‰ï¼›å…¶ä¸­ `siblings` ä»…å« `rfilename`ï¼‰ã€‚
3.  å®¢æˆ·ç«¯åŸºäºå“åº”æ„é€ ä¸‹è½½ URLï¼š
    - æ¨¡å‹ï¼š`{HF_ENDPOINT}/{repo_id}/resolve/{revision}/{filename}`
    - æ•°æ®é›†ï¼š`{HF_ENDPOINT}/datasets/{dataset_id}/resolve/{revision}/{filename}`ï¼ˆæ”¯æŒå­è·¯å¾„ `filename`ï¼‰
4.  æœåŠ¡é€šè¿‡ `/{repo_id:path}/resolve/{revision}/{filename:path}` è·¯ç”±å°†å¯¹åº”æ–‡ä»¶ä»¥ `FileResponse` è¿”å›ï¼ˆ`filename` æ”¯æŒå­ç›®å½•ï¼‰ã€‚

## â• æ·»åŠ æ›´å¤šæ¨¡å‹

æ·»åŠ æ–°çš„æ¨¡å‹éå¸¸ç®€å•ï¼š

1.  åœ¨ `fake_hub` ç›®å½•ä¸‹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶å¤¹ï¼Œæ–‡ä»¶å¤¹åç§°å°±æ˜¯ä½ çš„æ¨¡å‹ `repo_id`ã€‚ä¾‹å¦‚ï¼Œè¦æ·»åŠ  `bert-base-uncased`ï¼Œå°±åˆ›å»ºä¸€ä¸ªåä¸º `bert-base-uncased` çš„æ–‡ä»¶å¤¹ã€‚
    ```bash
    mkdir fake_hub/bert-base-uncased
    ```
2.  å°†è¯¥æ¨¡å‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆ`config.json`, `pytorch_model.bin` ç­‰ï¼‰å¤åˆ¶åˆ°è¿™ä¸ªæ–°åˆ›å»ºçš„æ–‡ä»¶å¤¹ä¸­ã€‚
3.  **æ— éœ€é‡å¯æœåŠ¡**ã€‚FastAPI æœåŠ¡ä¼šåœ¨ä¸‹æ¬¡æ”¶åˆ°è¯·æ±‚æ—¶è‡ªåŠ¨å‘ç°è¿™äº›æ–°æ–‡ä»¶ã€‚

ç°åœ¨ä½ å°±å¯ä»¥é€šè¿‡ `hf download bert-base-uncased --local-dir ./downloaded_bert` æ¥ä¸‹è½½ä½ çš„æ–°æ¨¡å‹äº†ã€‚

## ğŸ§ª è‡ªæ£€ä¸æ’é”™

- å¿«é€Ÿæ£€æŸ¥ APIï¼š
  ```bash
  curl -s $HF_ENDPOINT/api/models/gpt2 | head -c 200; echo
  curl -s $HF_ENDPOINT/api/models/gpt2/revision/main | head -c 200; echo
  # Range åˆ†æ®µä¸‹è½½éªŒè¯ï¼ˆå‰ 10 å­—èŠ‚ï¼‰
  curl -s -H 'Range: bytes=0-9' -i $HF_ENDPOINT/gpt2/resolve/main/config.json | sed -n '1,10p'
  ```
- è·¯ç”± 404ï¼šç¡®è®¤ä½¿ç”¨ `{repo_id:path}` ä»¥æ”¯æŒç»„ç»‡åï¼ˆå¦‚ `openai/gpt-oss-20b`ï¼‰ï¼Œå¹¶ç¡®ä¿ `FAKE_HUB_ROOT` æŒ‡å‘æ­£ç¡®æ ¹ï¼ˆå¯åŠ¨æ—¥å¿—ä¼šæ‰“å°ï¼‰ã€‚
- ä¸‹è½½ä¸ºç©º/å¤±è´¥ï¼šç¡®è®¤æ¨¡å‹æ–‡ä»¶ä½äº `fake_hub/gpt2/`ï¼ˆä¾‹å¦‚ `config.json`, `pytorch_model.bin`ï¼‰ã€‚
- å¯é€‰ï¼šé™å®šç¼“å­˜ç›®å½•ï¼Œé¿å…æ±¡æŸ“å…¨å±€ç¼“å­˜ï¼š
  ```bash
  export HF_HOME=$PWD/.hf_home
  ```

é™„ï¼šå¿«é€Ÿæ£€æŸ¥ `paths-info` ä¸ Range
```bash
# è·¯å¾„ä¿¡æ¯
curl -s -X POST "$HF_ENDPOINT/api/models/gpt2/paths-info/fakesha-main" -H 'content-type: application/json' -d '{"paths":[""],"expand":true}' | head -c 200; echo
curl -s -X POST "$HF_ENDPOINT/api/datasets/HuggingFaceFW/finepdfs/paths-info/fakesha-main" -H 'content-type: application/json' -d '{}'

# Range åˆ†æ®µéªŒè¯
curl -i -H 'Range: bytes=0-9' "$HF_ENDPOINT/gpt2/resolve/main/config.json" | sed -n '1,15p'
```

## âœ… é›†æˆæµ‹è¯•

æœ¬ä»“åº“æä¾›ä¸ `hf-mirror.com` çš„ç»“æ„å¯¹é½æµ‹è¯•ï¼š

```bash
uv run pytest -vs tests/test_api_compat.py
```

æµ‹è¯•å†…å®¹ï¼š
- å¯¹æ¯” `GET /api/models/gpt2` ä¸ `GET /api/models/gpt2/revision/main` çš„å­—æ®µé›†åˆä¸ç±»å‹ã€‚
- æ ¡éªŒæ–‡ä»¶è·¯ç”± `HEAD/GET` è¡Œä¸ºä¸å¿…è¦å“åº”å¤´ã€‚
- 404/4xx å¼‚å¸¸è·¯å¾„ä¸€è‡´æ€§ï¼ˆé•œåƒç«™å¯èƒ½è¿”å› 401/404ï¼Œå·²åšå…¼å®¹æ–­è¨€ï¼‰ã€‚

å¦å¤–æä¾›æ•°æ®é›†å…¼å®¹æ€§æµ‹è¯•ï¼ˆå¯¹ `HuggingFaceFW/finepdfs`ï¼‰ï¼š

```bash
uv run pytest -vs tests/test_dataset_api_compat.py
```

æµ‹è¯•å†…å®¹ï¼š
- `GET /api/datasets/...` ä¸ `GET /api/datasets/.../revision/main` æœ¬åœ°å­—æ®µåº”ä¸ºè¿œç«¯å­—æ®µå­é›†ï¼Œä¸”ç±»å‹ä¸€è‡´ã€‚
- æ ¡éªŒ `HEAD/GET` è¡Œä¸ºä¸å¿…è¦å“åº”å¤´ï¼ŒåŒ…å«å­è·¯å¾„æ–‡ä»¶ï¼ˆå¦‚ `data/*.jsonl`ï¼‰ã€‚
- 404/4xx å¼‚å¸¸è·¯å¾„ä¸€è‡´æ€§ã€‚

## ğŸ“œ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MIT è®¸å¯è¯](https://opensource.org/licenses/MIT)ã€‚
